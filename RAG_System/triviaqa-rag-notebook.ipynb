{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installation","metadata":{}},{"cell_type":"code","source":"%%writefile requirements.txt\ndatasets\ntransformers\nsentence-transformers\nchromadb\nlangchain\nlangchain-community\nlangchain-chroma\nlangchain-huggingface\nfastapi\nuvicorn\npython-dotenv\nbitsandbytes\naccelerate\nnest-asyncio\ntorch\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"execution":{"iopub.status.idle":"2025-12-26T21:03:02.427708Z","shell.execute_reply.started":"2025-12-26T21:02:57.697855Z","shell.execute_reply":"2025-12-26T21:03:02.426758Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (4.4.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (4.57.1)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (5.1.1)\nRequirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (1.4.0)\nRequirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.3.27)\nRequirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.3.31)\nRequirement already satisfied: langchain-chroma in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.2.6)\nRequirement already satisfied: langchain-huggingface in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.3.1)\nRequirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (0.119.1)\nRequirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (0.38.0)\nRequirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (1.1.1)\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.49.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (1.11.0)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (1.6.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (2.8.0+cu126)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 1)) (3.20.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 1)) (2.0.2)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 1)) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 1)) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 1)) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 1)) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 1)) (0.28.1)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 1)) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 1)) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 1)) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 1)) (2025.10.0)\nRequirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 1)) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 1)) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 1)) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (0.6.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r requirements.txt (line 3)) (1.6.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r requirements.txt (line 3)) (1.15.3)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r requirements.txt (line 3)) (11.3.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r requirements.txt (line 3)) (4.15.0)\nRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (1.3.0)\nRequirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (2.12.5)\nRequirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (1.4.3)\nRequirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (5.4.0)\nRequirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (1.23.2)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (1.39.1)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (1.39.1)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (1.39.1)\nRequirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (0.48.9)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (1.75.1)\nRequirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (5.0.0)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (0.20.0)\nRequirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (33.1.0)\nRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (8.5.0)\nRequirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (5.2.0)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (3.11.3)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (14.2.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb->-r requirements.txt (line 4)) (4.25.1)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain->-r requirements.txt (line 5)) (0.3.79)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain->-r requirements.txt (line 5)) (0.3.11)\nRequirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain->-r requirements.txt (line 5)) (0.4.37)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain->-r requirements.txt (line 5)) (2.0.45)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 6)) (3.13.2)\nRequirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 6)) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 6)) (2.11.0)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r requirements.txt (line 6)) (0.4.3)\nRequirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi->-r requirements.txt (line 9)) (0.48.0)\nRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn->-r requirements.txt (line 10)) (8.3.1)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn->-r requirements.txt (line 10)) (0.16.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate->-r requirements.txt (line 13)) (5.9.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 15)) (3.4.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 6)) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 6)) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 6)) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 6)) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 6)) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 6)) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 6)) (1.22.0)\nRequirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 4)) (1.2.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 6)) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 6)) (0.9.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 1)) (4.12.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 1)) (2025.11.12)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 1)) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 1)) (3.11)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets->-r requirements.txt (line 1)) (1.2.1rc0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 4)) (2025.9.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 4)) (0.37.0)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 4)) (0.27.1)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (1.17.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (2.38.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (1.9.0)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (2.0.0)\nRequirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (3.3.1)\nRequirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (2.6.2)\nRequirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (0.10)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain->-r requirements.txt (line 5)) (1.33)\nRequirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 5)) (1.0.0)\nRequirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 5)) (0.25.0)\nRequirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4)) (15.0.1)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4)) (25.9.23)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4)) (5.29.5)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 4)) (8.7.0)\nRequirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 4)) (1.71.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 4)) (1.39.1)\nRequirement already satisfied: opentelemetry-proto==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 4)) (1.39.1)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb->-r requirements.txt (line 4)) (0.60b1)\nRequirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 4)) (2.2.1)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 4)) (1.9.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb->-r requirements.txt (line 4)) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb->-r requirements.txt (line 4)) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb->-r requirements.txt (line 4)) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 1)) (3.4.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 4)) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 4)) (2.19.2)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 5)) (3.2.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 15)) (1.3.0)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 4)) (1.5.4)\nRequirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 4)) (0.7.1)\nRequirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 4)) (0.22.1)\nRequirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 4)) (1.1.1)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 4)) (15.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 15)) (3.0.3)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->-r requirements.txt (line 1)) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->-r requirements.txt (line 1)) (2025.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 3)) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 3)) (3.6.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (4.9.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 4)) (3.23.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain->-r requirements.txt (line 5)) (3.0.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirements.txt (line 4)) (0.1.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 6)) (1.1.0)\nRequirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4)) (10.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (0.6.1)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Modules","metadata":{}},{"cell_type":"markdown","source":"## Embedding Model","metadata":{}},{"cell_type":"code","source":"%%writefile embedding_model.py\nimport os\nfrom langchain_huggingface import HuggingFaceEmbeddings\n\nhf_token = os.getenv(\"HF_TOKEN\")\n\nMODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\nembedder = HuggingFaceEmbeddings(\n    model_name=MODEL_NAME,\n    model_kwargs={'device': 'cuda'} \n)\n\nprint(f\"[INFO] Embedding model '{MODEL_NAME}' loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T21:03:02.430270Z","iopub.execute_input":"2025-12-26T21:03:02.430555Z","iopub.status.idle":"2025-12-26T21:03:02.436347Z","shell.execute_reply.started":"2025-12-26T21:03:02.430527Z","shell.execute_reply":"2025-12-26T21:03:02.435636Z"}},"outputs":[{"name":"stdout","text":"Overwriting embedding_model.py\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport os\n\nuser_secrets = UserSecretsClient()\nos.environ['HF_TOKEN'] = user_secrets.get_secret(\"HF_TOKEN\")\n\n!python embedding_model.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T21:03:02.437175Z","iopub.execute_input":"2025-12-26T21:03:02.437459Z","iopub.status.idle":"2025-12-26T21:03:18.041891Z","shell.execute_reply.started":"2025-12-26T21:03:02.437429Z","shell.execute_reply":"2025-12-26T21:03:18.041112Z"}},"outputs":[{"name":"stdout","text":"2025-12-26 21:03:09.425999: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766782989.449697     535 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766782989.457084     535 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766782989.476196     535 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766782989.476255     535 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766782989.476260     535 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766782989.476263     535 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n[INFO] Embedding model 'sentence-transformers/all-MiniLM-L6-v2' loaded\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## LLM Model","metadata":{}},{"cell_type":"code","source":"%%writefile llm_model.py\nimport torch\nimport os\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n\nhf_token = os.getenv(\"HF_TOKEN\")\n\nLLM_MODEL = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n)\n\nprint(f\"[INFO] Loading tokenizer for Mistral...\")\ntokenizer = AutoTokenizer.from_pretrained(LLM_MODEL, token=hf_token)\n\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\nprint(f\"[INFO] Loading Mistral-7B-v0.2 in 4-bit...\")\nmodel = AutoModelForCausalLM.from_pretrained(\n    LLM_MODEL,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    token=hf_token\n)\n\nprint(f\"[INFO] LLM model loaded successfully on {model.device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T21:03:18.043272Z","iopub.execute_input":"2025-12-26T21:03:18.043598Z","iopub.status.idle":"2025-12-26T21:03:18.049432Z","shell.execute_reply.started":"2025-12-26T21:03:18.043567Z","shell.execute_reply":"2025-12-26T21:03:18.048763Z"}},"outputs":[{"name":"stdout","text":"Overwriting llm_model.py\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nos.environ['HF_TOKEN'] = user_secrets.get_secret(\"HF_TOKEN\")\n!python llm_model.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T21:03:18.050534Z","iopub.execute_input":"2025-12-26T21:03:18.050819Z","iopub.status.idle":"2025-12-26T21:04:04.619661Z","shell.execute_reply.started":"2025-12-26T21:03:18.050796Z","shell.execute_reply":"2025-12-26T21:04:04.618919Z"}},"outputs":[{"name":"stdout","text":"[INFO] Loading tokenizer for Mistral...\n[INFO] Loading Mistral-7B-v0.2 in 4-bit...\n2025-12-26 21:03:25.108056: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766783005.130742     556 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766783005.137831     556 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766783005.156178     556 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766783005.156215     556 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766783005.156242     556 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766783005.156255     556 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nLoading checkpoint shards: 100%|██████████████████| 3/3 [00:26<00:00,  8.91s/it]\ngeneration_config.json: 100%|███████████████████| 111/111 [00:00<00:00, 831kB/s]\n[INFO] LLM model loaded successfully on cuda:0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"%%writefile preprocess.py\nimport os\nimport json\nfrom datasets import load_dataset\ntry:\n    from embedding_model import embedder\n    from llm_model import tokenizer\n    print(\"[SUCCESS] Imported embedder and tokenizer\")\nexcept ImportError:\n    print(\"[ERROR] Could not find embedding_model.py or llm_model.py. Make sure to run those cells first!\")\n\nprint(\"Tokenizer loaded successfully\")\n\n\ndef load_triviaqa_subset(n_samples=700):\n    print(f\"[load_triviaqa_subset] Loading {n_samples} samples from TriviaQA...\")\n    dataset = load_dataset(\"mandarjoshi/trivia_qa\", \"unfiltered\", split=f\"train[:{n_samples}]\")\n    docs = []\n\n    for item in dataset:\n        sr = item.get(\"search_results\", {})\n        contexts = sr.get(\"search_context\", [])\n\n        for ctx in contexts:\n            if ctx and ctx.strip():\n                docs.append({\n                    \"doc_id\": item[\"question_id\"],\n                    \"text\": ctx.strip()\n                })\n\n    print(f\"[load_triviaqa_subset] Docs extracted: {len(docs)}\")\n    # if docs:\n    #     print(\"[load_triviaqa_subset] Example doc:\", docs[0])\n    return docs\n\nimport re\n\ndef clean_text(text, min_length=15):\n    if not text:\n        return None\n    cleaned = text.strip()\n    cleaned = re.sub(r'\\s+', ' ', cleaned)\n    if len(cleaned) < min_length:\n        return None\n\n    return cleaned\n\ndef chunk_text(text, min_tokens=50, max_tokens=256, overlap=50): \n    token_ids = tokenizer(text, add_special_tokens=False)[\"input_ids\"]\n    if len(token_ids) < max_tokens:\n       return [tokenizer.decode(token_ids)]\n    \n    chunks = []\n    start = 0\n    while start < len(token_ids):\n        end = start + max_tokens\n        chunk_ids = token_ids[start:end]\n        chunks.append(tokenizer.decode(chunk_ids))\n        start += max_tokens - overlap \n    return chunks\n\ndef preprocess_triviaqa(n_samples=700, min_tokens_chunk=50, max_tokens_chunk=256, overlap_chunk=50):\n    print(f\"[preprocess_triviaqa] Starting preprocessing for {n_samples} samples...\")\n    docs = load_triviaqa_subset(n_samples)\n    final_chunks = []\n\n    for idx, d in enumerate(docs):\n        cleaned = clean_text(d[\"text\"])\n        if not cleaned:\n            print(f\"[clean_text] Doc {d['doc_id']} skipped (too short)\")\n            continue\n\n        chunks = chunk_text(cleaned, min_tokens=min_tokens_chunk, max_tokens=max_tokens_chunk, overlap=overlap_chunk)\n        if not chunks:\n            print(f\"[chunk_text] Doc {d['doc_id']} produced 0 chunks\")\n            continue\n\n        for i, ch in enumerate(chunks):\n            final_chunks.append({\n                \"doc_id\": d[\"doc_id\"],\n                \"chunk_id\": i,\n                \"text\": ch\n            })\n        if idx < 3: \n            print(f\"[preprocess_triviaqa] Doc {d['doc_id']} → {len(chunks)} chunks\")\n\n    print(f\"[preprocess_triviaqa] Total chunks generated: {len(final_chunks)}\")\n    if final_chunks:\n        print(\"[preprocess_triviaqa] Example chunk:\", final_chunks[0])\n    return final_chunks\n\ndef store_chunks_metadata(final_chunks, output_file=\"chunks_metadata.json\"):\n    metadata_list = []\n\n    for chunk in final_chunks:\n        text = chunk.get(\"text\", \"\")\n        meta = {\n            \"doc_id\": chunk.get(\"doc_id\"),\n            \"chunk_id\": chunk.get(\"chunk_id\"),\n            \"text\": text,  \n            \"text_length\": len(text),\n            \"num_tokens\": len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n        }\n        metadata_list.append(meta)\n    \n    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n        json.dump(metadata_list, f, ensure_ascii=False, indent=2)\n    \n    print(f\"[store_chunks_metadata] Stored metadata for {len(metadata_list)} chunks in {output_file}\")\n    return metadata_list\n\n\n\n\n#TEST\nif __name__ == \"__main__\":\n    print(\"[main] Running full preprocessing test...\")\n    final_chunks = preprocess_triviaqa(n_samples=700, min_tokens_chunk=50, max_tokens_chunk=256, overlap_chunk=50)\n\n    print(f\"[main] Test complete. Total chunks generated: {len(final_chunks)}\")\n    if final_chunks:\n        print(\"[main] Example chunk:\", final_chunks[0])\n    chunks_metadata = store_chunks_metadata(final_chunks)\n    print(chunks_metadata[:2])  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T21:04:04.620990Z","iopub.execute_input":"2025-12-26T21:04:04.621333Z","iopub.status.idle":"2025-12-26T21:04:04.629387Z","shell.execute_reply.started":"2025-12-26T21:04:04.621297Z","shell.execute_reply":"2025-12-26T21:04:04.628568Z"}},"outputs":[{"name":"stdout","text":"Overwriting preprocess.py\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\nimport sys\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nos.environ['HF_TOKEN'] = user_secrets.get_secret(\"HF_TOKEN\")\nsys.path.append('/kaggle/working')\n\n!python preprocess.py","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"execution":{"iopub.status.busy":"2025-12-26T21:04:04.630454Z","iopub.execute_input":"2025-12-26T21:04:04.630747Z","iopub.status.idle":"2025-12-26T21:07:26.789023Z","shell.execute_reply.started":"2025-12-26T21:04:04.630718Z","shell.execute_reply":"2025-12-26T21:07:26.788298Z"}},"outputs":[{"name":"stdout","text":"2025-12-26 21:04:11.868656: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766783051.891380     600 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766783051.898564     600 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766783051.916617     600 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766783051.916648     600 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766783051.916652     600 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766783051.916655     600 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n[INFO] Embedding model 'sentence-transformers/all-MiniLM-L6-v2' loaded\n[INFO] Loading tokenizer for Mistral...\n[INFO] Loading Mistral-7B-v0.2 in 4-bit...\nLoading checkpoint shards: 100%|██████████████████| 3/3 [00:17<00:00,  5.96s/it]\n[INFO] LLM model loaded successfully on cuda:0\n[SUCCESS] Imported embedder and tokenizer\nTokenizer loaded successfully\n[main] Running full preprocessing test...\n[preprocess_triviaqa] Starting preprocessing for 700 samples...\n[load_triviaqa_subset] Loading 700 samples from TriviaQA...\nResolving data files: 100%|██████████████████| 26/26 [00:00<00:00, 25191.02it/s]\nResolving data files: 100%|██████████████████| 47/47 [00:00<00:00, 30893.64it/s]\n[load_triviaqa_subset] Docs extracted: 5541\n[preprocess_triviaqa] Doc tc_0 → 41 chunks\n[preprocess_triviaqa] Doc tc_0 → 9 chunks\n[preprocess_triviaqa] Doc tc_0 → 20 chunks\n[preprocess_triviaqa] Total chunks generated: 128151\n[preprocess_triviaqa] Example chunk: {'doc_id': 'tc_0', 'chunk_id': 0, 'text': 'Peanuts | Peanuts Wiki | Fandom powered by Wikia Charles M. Schulz drawing Snoopy . Peanuts is a syndicated daily and Sunday comic strip written and illustrated by Charles M. Schulz , which ran from October 2, 1950, to February 13, 2000 (the day after Schulz\\'s death). In total 17,897 different Peanuts strips were published. The strip was one of the most popular and influential in the history of the medium, and considered the most beloved comic strips of all time. It was \"arguably the longest story ever told by one human being,\\'\"\\' according to Professor Robert Thompson of Syracuse University. At its peak, Peanuts ran in over 2,600 newspapers, with a readership of 355 million in 75 countries, and was translated into 21 languages. It helped to cement the four-panel gag strip as the standard in the United States. Reprints of the strip are still syndicated and run in many newspapers. In addition, Peanuts achieved considerable success for its television specials, several of which'}\n[main] Test complete. Total chunks generated: 128151\n[main] Example chunk: {'doc_id': 'tc_0', 'chunk_id': 0, 'text': 'Peanuts | Peanuts Wiki | Fandom powered by Wikia Charles M. Schulz drawing Snoopy . Peanuts is a syndicated daily and Sunday comic strip written and illustrated by Charles M. Schulz , which ran from October 2, 1950, to February 13, 2000 (the day after Schulz\\'s death). In total 17,897 different Peanuts strips were published. The strip was one of the most popular and influential in the history of the medium, and considered the most beloved comic strips of all time. It was \"arguably the longest story ever told by one human being,\\'\"\\' according to Professor Robert Thompson of Syracuse University. At its peak, Peanuts ran in over 2,600 newspapers, with a readership of 355 million in 75 countries, and was translated into 21 languages. It helped to cement the four-panel gag strip as the standard in the United States. Reprints of the strip are still syndicated and run in many newspapers. In addition, Peanuts achieved considerable success for its television specials, several of which'}\n[store_chunks_metadata] Stored metadata for 128151 chunks in chunks_metadata.json\n[{'doc_id': 'tc_0', 'chunk_id': 0, 'text': 'Peanuts | Peanuts Wiki | Fandom powered by Wikia Charles M. Schulz drawing Snoopy . Peanuts is a syndicated daily and Sunday comic strip written and illustrated by Charles M. Schulz , which ran from October 2, 1950, to February 13, 2000 (the day after Schulz\\'s death). In total 17,897 different Peanuts strips were published. The strip was one of the most popular and influential in the history of the medium, and considered the most beloved comic strips of all time. It was \"arguably the longest story ever told by one human being,\\'\"\\' according to Professor Robert Thompson of Syracuse University. At its peak, Peanuts ran in over 2,600 newspapers, with a readership of 355 million in 75 countries, and was translated into 21 languages. It helped to cement the four-panel gag strip as the standard in the United States. Reprints of the strip are still syndicated and run in many newspapers. In addition, Peanuts achieved considerable success for its television specials, several of which', 'text_length': 988, 'num_tokens': 256}, {'doc_id': 'tc_0', 'chunk_id': 1, 'text': \"the four-panel gag strip as the standard in the United States. Reprints of the strip are still syndicated and run in many newspapers. In addition, Peanuts achieved considerable success for its television specials, several of which, including A Charlie Brown Christmas and It's the Great Pumpkin, Charlie Brown won or were nominated for Emmys. The holiday specials remain quite popular to this day, and are currently broadcast on ABC in the United States during the appropriate season. Contents Peanuts 1940s Front cover of a collection of Li'l Folks comic strips. Peanuts had its origin in Li'l Folks , a weekly panel comic that appeared in Schulz's hometown paper, the St. Paul Pioneer Press, from 1947 to 1950. He first used the name Charlie Brown for a character there, although he used the name on four different occasions in Li'l Folks for different boys. The series also featured a dog that looked a lot like Snoopy . In 1948, Schulz sold a cartoon to the Saturday Evening Post; seventeen single-panel cartoons by Schulz would\", 'text_length': 1032, 'num_tokens': 256}]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import json\nimport numpy as np\nfrom preprocess import load_triviaqa_subset\n\n\n# Load orignal documents\nraw_docs = load_triviaqa_subset(n_samples=700)\n\noriginal_lengths = [\n    len(doc[\"text\"].split())\n    for doc in raw_docs\n]\norig_p50 = np.percentile(original_lengths, 50)\norig_p90 = np.percentile(original_lengths, 90)\norig_max = np.max(original_lengths)\n\nprint(\"\\n---Original Paragraph Analysis (Before Chunking) ---\")\nprint(f\"Total Paragraphs: {len(original_lengths)}\")\nprint(f\"Median Length (P50): {orig_p50:.2f} words\")\nprint(f\"90th Percentile (P90): {orig_p90:.2f} words\")\nprint(f\"Max Paragraph Length: {orig_max} words\")\n\n\n# Load CHUNKED documents\nwith open(\"chunks_metadata.json\", \"r\", encoding=\"utf-8\") as f:\n    chunks = json.load(f)\n\nchunk_word_counts = [\n    len(chunk[\"text\"].split())\n    for chunk in chunks\n]\n\nchunk_avg = np.mean(chunk_word_counts)\nchunk_p90 = np.percentile(chunk_word_counts, 90)\nchunk_max = np.max(chunk_word_counts)\n\nprint(\"\\n--- Chunk Statistics (After Chunking) ---\")\nprint(f\"Total Chunks: {len(chunks)}\")\nprint(f\"Average Words per Chunk: {chunk_avg:.2f}\")\nprint(f\"90th Percentile (P90): {chunk_p90:.2f} words\")\nprint(f\"Max Words in a Chunk: {chunk_max} words\")\n\n\n# Comparison Summary\nprint(\"\\n--- Chunking Effect Summary ---\")\nprint(f\"Original P90 → {orig_p90:.2f} words\")\nprint(f\"Chunked  P90 → {chunk_p90:.2f} words\")\nprint(f\"Reduction Factor ≈ {(orig_p90 / chunk_p90):.2f}x\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T21:07:26.790413Z","iopub.execute_input":"2025-12-26T21:07:26.790717Z","iopub.status.idle":"2025-12-26T21:08:06.331940Z","shell.execute_reply.started":"2025-12-26T21:07:26.790685Z","shell.execute_reply":"2025-12-26T21:08:06.331164Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true}},"outputs":[{"name":"stderr","text":"2025-12-26 21:07:34.053428: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766783254.077646     494 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766783254.084813     494 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766783254.103943     494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766783254.103964     494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766783254.103967     494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766783254.103969     494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"[INFO] Embedding model 'sentence-transformers/all-MiniLM-L6-v2' loaded\n[INFO] Loading tokenizer for Mistral...\n[INFO] Loading Mistral-7B-v0.2 in 4-bit...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28769d1dde3d481c80e8caa80fcaf732"}},"metadata":{}},{"name":"stdout","text":"[INFO] LLM model loaded successfully on cuda:0\n[SUCCESS] Imported embedder and tokenizer\nTokenizer loaded successfully\n[load_triviaqa_subset] Loading 700 samples from TriviaQA...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da00092bb8fc4e999ed7972925a8718f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/47 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b53204b30714334ab97bd97a6a9720b"}},"metadata":{}},{"name":"stdout","text":"[load_triviaqa_subset] Docs extracted: 5541\n\n---Original Paragraph Analysis (Before Chunking) ---\nTotal Paragraphs: 5541\nMedian Length (P50): 1038.00 words\n90th Percentile (P90): 6098.00 words\nMax Paragraph Length: 89615 words\n\n--- Chunk Statistics (After Chunking) ---\nTotal Chunks: 128151\nAverage Words per Chunk: 158.20\n90th Percentile (P90): 193.00 words\nMax Words in a Chunk: 234 words\n\n--- Chunking Effect Summary ---\nOriginal P90 → 6098.00 words\nChunked  P90 → 193.00 words\nReduction Factor ≈ 31.60x\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Vector DB","metadata":{}},{"cell_type":"code","source":"# #Delete chroma_db\n# import shutil\n# import os\n# db_path = \"/kaggle/working/chroma_db\"\n\n# if os.path.exists(db_path):\n#     shutil.rmtree(db_path)\n#     print(f\"Deleted old database at {db_path}\")\n# else:\n#     print(\"No old database found, starting fresh!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T21:08:06.333152Z","iopub.execute_input":"2025-12-26T21:08:06.334426Z","iopub.status.idle":"2025-12-26T21:08:06.338334Z","shell.execute_reply.started":"2025-12-26T21:08:06.334393Z","shell.execute_reply":"2025-12-26T21:08:06.337643Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"%%writefile vector_store.py\nimport json\nimport uuid\nimport os\nimport shutil\nfrom langchain_community.vectorstores import Chroma\nfrom embedding_model import embedder \n\npersist_dir = \"/kaggle/working/chroma_db\"\nif os.path.exists(persist_dir):\n    shutil.rmtree(persist_dir)\n    print(f\"[INFO] Deleted old database at {persist_dir}\")\n\nif not os.path.exists(\"chunks_metadata.json\"):\n    print(\"[ERROR] chunks_metadata.json not found! Please run preprocess.py first.\")\nelse:\n    with open(\"chunks_metadata.json\", \"r\", encoding=\"utf-8\") as f:\n        chunks = json.load(f)\n    print(f\"[INFO] Loaded {len(chunks)} chunks from JSON\")\n\n    vectorstore = Chroma(\n        persist_directory=persist_dir,\n        embedding_function=embedder\n    )\n\n    texts = [chunk[\"text\"] for chunk in chunks]\n    ids = [f'{chunk[\"doc_id\"]}_{chunk[\"chunk_id\"]}_{uuid.uuid4().hex}' for chunk in chunks]\n\n    print(f\"[INFO] Generating embeddings for {len(texts)} texts using GPU...\")\n    all_embeddings = embedder.embed_documents(texts)\n\n    batch_size = 2000\n    for start in range(0, len(texts), batch_size):\n        end = start + batch_size\n        batch_ids = ids[start:end]\n        batch_texts = texts[start:end]\n        batch_embeddings = all_embeddings[start:end]\n\n        vectorstore._collection.add(\n            ids=batch_ids,\n            documents=batch_texts,\n            embeddings=batch_embeddings\n        )\n        print(f\"[INFO] Stored batch {start}–{min(end, len(texts))} items\")\n\n    vectorstore.persist()\n    print(f\"[INFO] Stored total {len(texts)} embeddings in ChromaDB at '{persist_dir}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T21:08:06.339320Z","iopub.execute_input":"2025-12-26T21:08:06.339569Z","iopub.status.idle":"2025-12-26T21:08:06.357022Z","shell.execute_reply.started":"2025-12-26T21:08:06.339519Z","shell.execute_reply":"2025-12-26T21:08:06.356025Z"}},"outputs":[{"name":"stdout","text":"Writing vector_store.py\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nos.environ['HF_TOKEN'] = user_secrets.get_secret(\"HF_TOKEN\")\n\n!python vector_store.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T21:08:06.360368Z","iopub.execute_input":"2025-12-26T21:08:06.360674Z","iopub.status.idle":"2025-12-26T21:17:24.837106Z","shell.execute_reply.started":"2025-12-26T21:08:06.360647Z","shell.execute_reply":"2025-12-26T21:17:24.836008Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"2025-12-26 21:08:13.533698: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766783293.557087     693 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766783293.563930     693 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766783293.581871     693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766783293.581917     693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766783293.581921     693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766783293.581924     693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n[INFO] Embedding model 'sentence-transformers/all-MiniLM-L6-v2' loaded\n[INFO] Loaded 128151 chunks from JSON\n/kaggle/working/vector_store.py:20: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n  vectorstore = Chroma(\n[INFO] Generating embeddings for 128151 texts using GPU...\n[INFO] Stored batch 0–2000 items\n[INFO] Stored batch 2000–4000 items\n[INFO] Stored batch 4000–6000 items\n[INFO] Stored batch 6000–8000 items\n[INFO] Stored batch 8000–10000 items\n[INFO] Stored batch 10000–12000 items\n[INFO] Stored batch 12000–14000 items\n[INFO] Stored batch 14000–16000 items\n[INFO] Stored batch 16000–18000 items\n[INFO] Stored batch 18000–20000 items\n[INFO] Stored batch 20000–22000 items\n[INFO] Stored batch 22000–24000 items\n[INFO] Stored batch 24000–26000 items\n[INFO] Stored batch 26000–28000 items\n[INFO] Stored batch 28000–30000 items\n[INFO] Stored batch 30000–32000 items\n[INFO] Stored batch 32000–34000 items\n[INFO] Stored batch 34000–36000 items\n[INFO] Stored batch 36000–38000 items\n[INFO] Stored batch 38000–40000 items\n[INFO] Stored batch 40000–42000 items\n[INFO] Stored batch 42000–44000 items\n[INFO] Stored batch 44000–46000 items\n[INFO] Stored batch 46000–48000 items\n[INFO] Stored batch 48000–50000 items\n[INFO] Stored batch 50000–52000 items\n[INFO] Stored batch 52000–54000 items\n[INFO] Stored batch 54000–56000 items\n[INFO] Stored batch 56000–58000 items\n[INFO] Stored batch 58000–60000 items\n[INFO] Stored batch 60000–62000 items\n[INFO] Stored batch 62000–64000 items\n[INFO] Stored batch 64000–66000 items\n[INFO] Stored batch 66000–68000 items\n[INFO] Stored batch 68000–70000 items\n[INFO] Stored batch 70000–72000 items\n[INFO] Stored batch 72000–74000 items\n[INFO] Stored batch 74000–76000 items\n[INFO] Stored batch 76000–78000 items\n[INFO] Stored batch 78000–80000 items\n[INFO] Stored batch 80000–82000 items\n[INFO] Stored batch 82000–84000 items\n[INFO] Stored batch 84000–86000 items\n[INFO] Stored batch 86000–88000 items\n[INFO] Stored batch 88000–90000 items\n[INFO] Stored batch 90000–92000 items\n[INFO] Stored batch 92000–94000 items\n[INFO] Stored batch 94000–96000 items\n[INFO] Stored batch 96000–98000 items\n[INFO] Stored batch 98000–100000 items\n[INFO] Stored batch 100000–102000 items\n[INFO] Stored batch 102000–104000 items\n[INFO] Stored batch 104000–106000 items\n[INFO] Stored batch 106000–108000 items\n[INFO] Stored batch 108000–110000 items\n[INFO] Stored batch 110000–112000 items\n[INFO] Stored batch 112000–114000 items\n[INFO] Stored batch 114000–116000 items\n[INFO] Stored batch 116000–118000 items\n[INFO] Stored batch 118000–120000 items\n[INFO] Stored batch 120000–122000 items\n[INFO] Stored batch 122000–124000 items\n[INFO] Stored batch 124000–126000 items\n[INFO] Stored batch 126000–128000 items\n[INFO] Stored batch 128000–128151 items\n/kaggle/working/vector_store.py:45: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n  vectorstore.persist()\n[INFO] Stored total 128151 embeddings in ChromaDB at '/kaggle/working/chroma_db'\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### Test chroma_db Retrival","metadata":{}},{"cell_type":"code","source":"from langchain_community.vectorstores import Chroma\nfrom embedding_model import embedder\nimport os\n\npersist_dir = \"/kaggle/working/chroma_db\"\n\nif os.path.exists(persist_dir):\n    db = Chroma(persist_directory=persist_dir, embedding_function=embedder)\n    \n    query = \"Which number Beethoven symphony is known as ‘The Pastoral’?\"\n    results = db.similarity_search(query, k=5) \n\n    print(f\"🔍 Searching for: '{query}'\\n\" + \"=\"*50)\n    for i, res in enumerate(results):\n        print(f\"📄 Result {i+1}:\")\n        print(f\"{res.page_content[:400]}...\")\n        print(\"-\" * 30)\nelse:\n    print(\"❌ Database not found! Please run 'python vector_store.py' first.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T22:20:42.341539Z","iopub.execute_input":"2025-12-26T22:20:42.342264Z","iopub.status.idle":"2025-12-26T22:20:42.373186Z","shell.execute_reply.started":"2025-12-26T22:20:42.342212Z","shell.execute_reply":"2025-12-26T22:20:42.372249Z"}},"outputs":[{"name":"stdout","text":"🔍 Searching for: 'Which number Beethoven symphony is known as ‘The Pastoral’?'\n==================================================\n📄 Result 1:\nboro 1969: Beethoven: First, Second, Fourth, Sixth (\"Pastorale\"), and Seventh Symphonies 1974: El Pessebre (The Manger) oratorio See also...\n------------------------------\n📄 Result 2:\n48] BEETHOVEN. Ludwig von Beethoven was born Dec. 16, 1770, at Bonn, Germany. His father was a court-singer in the Chapel of the Elector of Cologne. The great composer studied in Vienna with Haydn, with whom he did not always agree, however, and afterwards with Albrechtsberger. His first symphony appeared in 1801,—his earlier symphonies, in what is called his first period, being written in the Moz...\n------------------------------\n📄 Result 3:\nlive performances), including: Haydn: \"Farewell\" Symphony (No. 45) and Mozart \"Linz\" Symphony (No. 36) Beethoven: Trio Op. 1 No. 3, with Yehudi and Hephzibah Menuhin Schubert: String Quintet, with the Budapest String Quartet 1961: Mendelssohn: Piano Trio No. 1 with Alexander Schneider and Mieczysław Horszowski (Recorded live November 13, 1961 at the White House) 1963: Beethoven: Eighth Symphony 19...\n------------------------------\n📄 Result 4:\nis very effective. The chorus then re-enter and indicate the madness of the Count in words, the following sample of which will show their unsingableness:— “Revenge fires his turbulent soul; No power his boundless rage can control.” The eighth number is another duet for the Countess and Mazeppa in the conventional Italian style. It is followed by a graceful aria for tenor, which leads up to the bes...\n------------------------------\n📄 Result 5:\n2, with Yehudi Menuhin and Mieczysław Horszowski Schumann: Trio No. 3, with Sándor Végh and Rudolf Serkin 1958: At Beethoven-Haus in Bonn (all live performances), including: Beethoven: Sonata Op. 5 No. 1, with Wilhelm Kempff Beethoven: Sonatas Op. 5 No. 2, Op. 102 No. 2, and the Horn Op. 17 transcription, with Mieczysław Horszowski Beethoven: Trios Op. 1 No. 3, and Op. 97, with Sándor Végh and Mie...\n------------------------------\n","output_type":"stream"}],"execution_count":54},{"cell_type":"markdown","source":"## Pipeline","metadata":{}},{"cell_type":"code","source":"%%writefile pipeline.py\nimport time\nimport re\nfrom transformers import pipeline\nfrom llm_model import model, tokenizer\nfrom embedding_model import embedder\nfrom langchain.chains import RetrievalQA\nfrom langchain_huggingface import HuggingFacePipeline\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_core.prompts import PromptTemplate\n\n\n# LLM pipeline \nraw_pipeline = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=64,         \n    temperature=0.0,            \n    do_sample=False,\n    return_full_text=False\n)\n\nllm_pipeline = HuggingFacePipeline(pipeline=raw_pipeline)\n\n\n#vector DB\npersist_dir = \"/kaggle/working/chroma_db\"\nvector_db = Chroma(\n    persist_directory=persist_dir,\n    embedding_function=embedder\n)\n\nretriever = vector_db.as_retriever(search_kwargs={\"k\":5})\n\n\n# prompt \nprompt_template = \"\"\"<s>[INST]\nYou are a STRICT answer-only bot.\n\nRules:\n- Answer ONLY using the context\n- Answer must be very short (1–3 words)\n- If the answer is not explicitly present, reply EXACTLY with:\nNot found in context\n- No explanations\n- No full sentences\n\nContext:\n{context}\n\nQuestion:\n{question}\n[/INST]\nAnswer:\n\"\"\"\n\nprompt = PromptTemplate(\n    input_variables=[\"context\", \"question\"],\n    template=prompt_template\n)\n\n\n# QA CHAIN  \nqa_chain = RetrievalQA.from_chain_type(\n    llm=llm_pipeline,\n    chain_type=\"stuff\",\n    retriever=retriever,\n    chain_type_kwargs={\"prompt\": prompt},\n)\n\n\n#  RAG Function\ndef run_rag(question: str):\n    start_time = time.time()\n    if question:\n        question = question.strip()  \n        question = re.sub(r'\\s+', ' ', question)  \n\n    # Handle empty or None queries \n    if not question or not question.strip():\n        latency_ms = int((time.time() - start_time) * 1000)\n        print(f\"[WARNING] Empty or None query received. Latency: {latency_ms}ms\")\n        return {\n            \"question\": question,\n            \"answer\": \"Empty query received\",\n            \"retrieved_context\": \"\",\n            \"latency_ms\": latency_ms\n        }\n\n    try:\n        # Retrieve context\n        docs = retriever.invoke(question)\n        context_string = \"\\n\".join(doc.page_content.strip() for doc in docs)\n\n        # Generate answer\n        response = qa_chain.invoke({\"query\": question})\n        raw_answer = response[\"result\"].strip()\n        answer = raw_answer.split(\"\\n\")[0].strip()\n\n        # Clean answer \n        if (\n            not answer\n            or len(answer.split()) > 3\n            or \"not found\" in answer.lower()\n            or \"context\" in answer.lower()\n            or \"does not\" in answer.lower()\n        ):\n            final_answer = \"Not found in context\"\n        else:\n            final_answer = answer.rstrip(\".\")\n\n        latency_ms = int((time.time() - start_time) * 1000)\n        return {\n            \"question\": question,\n            \"answer\": final_answer,\n            \"retrieved_context\": context_string,\n            \"latency_ms\": latency_ms\n        }\n\n    except Exception as e:\n        latency_ms = int((time.time() - start_time) * 1000)\n        print(f\"[ERROR] Exception during processing: {str(e)}. Latency: {latency_ms}ms\")\n        return {\n            \"question\": question,\n            \"answer\": \"Not found in context\",\n            \"retrieved_context\": \"\",\n            \"latency_ms\": latency_ms\n        }\n\n\n# TEST \nif __name__ == \"__main__\":\n    query = \"\tWhich country left the Commonwealthin 1972 and rejoined in 1989?\"\n    result = run_rag(query)\n    \n    print(\"--- RAG Result ---\")\n    print(f\"Question: {result['question']}\")\n    print(f\"Answer: {result['answer']}\")\n    print(f\"Latency: {result['latency_ms']} ms\")\n    print(\"\\n--- Context Found (Snippets) ---\")\n    print(result[\"retrieved_context\"][:500])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T22:10:28.163746Z","iopub.execute_input":"2025-12-26T22:10:28.164655Z","iopub.status.idle":"2025-12-26T22:10:28.173086Z","shell.execute_reply.started":"2025-12-26T22:10:28.164610Z","shell.execute_reply":"2025-12-26T22:10:28.172147Z"}},"outputs":[{"name":"stdout","text":"Overwriting pipeline.py\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nos.environ['HF_TOKEN'] = user_secrets.get_secret(\"HF_TOKEN\")\n\n!python pipeline.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T22:10:43.376429Z","iopub.execute_input":"2025-12-26T22:10:43.377406Z","iopub.status.idle":"2025-12-26T22:11:30.985502Z","shell.execute_reply.started":"2025-12-26T22:10:43.377364Z","shell.execute_reply":"2025-12-26T22:11:30.984698Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"2025-12-26 22:10:47.832494: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766787047.856402    1507 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766787047.863247    1507 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766787047.880986    1507 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766787047.881019    1507 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766787047.881025    1507 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766787047.881031    1507 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n[INFO] Loading tokenizer for Mistral...\n[INFO] Loading Mistral-7B-v0.2 in 4-bit...\nLoading checkpoint shards: 100%|██████████████████| 3/3 [00:15<00:00,  5.13s/it]\n[INFO] LLM model loaded successfully on cuda:0\n[INFO] Embedding model 'sentence-transformers/all-MiniLM-L6-v2' loaded\nDevice set to use cuda:0\nThe following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n/kaggle/working/pipeline.py:28: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n  vector_db = Chroma(\n--- RAG Result ---\nQuestion: Which country left the Commonwealthin 1972 and rejoined in 1989?\nAnswer: Not found in context\nLatency: 8983 ms\n\n--- Context Found (Snippets) ---\nformally relinquished rights 15 March 1991 Ghana: 6 March 1957 (from UK) Gibraltar : none (overseas territory of the UK) Greece: 1829 (from the Ottoman Empire) Greenland: none (part of the Kingdom of Denmark; self-governing overseas administrative division of Denmark since 1979) Grenada: 7 February 1974 (from UK) Guadeloupe: none (overseas department of France) Guam: none (territory of the US) Guatemala: 15 September 1821 (from Spain) Guernsey: none (British crown dependency) Guinea: 2 October 1\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"# APP","metadata":{}},{"cell_type":"code","source":"%%writefile app.py\nimport time\nimport json\nimport requests\nimport nest_asyncio\nimport uvicorn\nfrom threading import Thread\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom pipeline import run_rag   \n\napp = FastAPI()\n\nclass QueryRequest(BaseModel):\n    question: str\n\nclass QueryResponse(BaseModel):\n    question: str\n    answer: str\n    retrieved_context: str \n    latency_ms: int\n\n@app.post(\"/query\", response_model=QueryResponse)\ndef query_endpoint(req: QueryRequest):\n    result = run_rag(req.question)\n    return QueryResponse(\n        question=result.get(\"question\", req.question),\n        answer=result.get(\"answer\", \"No answer generated\"),\n        retrieved_context=result.get(\"retrieved_context\", \"\"),\n        latency_ms=result.get(\"latency_ms\", 0)\n    )\n\nnest_asyncio.apply()\n\ndef run_api():\n    uvicorn.run(app, host=\"0.0.0.0\", port=8050, log_level=\"error\")\n\nthread = Thread(target=run_api, daemon=True)\nthread.start()\n\nprint(\"[INFO] Waiting for server to stabilize...\")\ntime.sleep(15) \n\nurl = \"http://127.0.0.1:8050/query\"\npayload = {\"question\": \"Which country left the Commonwealthin 1972 and rejoined in 1989?\"}\n\ntry:\n    resp = requests.post(url, json=payload)\n    print(\"POST status:\", resp.status_code)\n    if resp.status_code == 200:\n        print(\"POST response:\")\n        print(json.dumps(resp.json(), indent=4))\n    else:\n        print(\"Error Response:\", resp.text)\nexcept Exception as e:\n    print(f\"[ERROR] Connection failed: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T22:12:11.326793Z","iopub.execute_input":"2025-12-26T22:12:11.327880Z","iopub.status.idle":"2025-12-26T22:12:11.334383Z","shell.execute_reply.started":"2025-12-26T22:12:11.327833Z","shell.execute_reply":"2025-12-26T22:12:11.333537Z"}},"outputs":[{"name":"stdout","text":"Overwriting app.py\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"!python app.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T22:12:20.692747Z","iopub.execute_input":"2025-12-26T22:12:20.693589Z","iopub.status.idle":"2025-12-26T22:13:25.591819Z","shell.execute_reply.started":"2025-12-26T22:12:20.693553Z","shell.execute_reply":"2025-12-26T22:13:25.590689Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"2025-12-26 22:12:25.521904: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766787145.547454    1568 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766787145.555812    1568 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766787145.576001    1568 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766787145.576041    1568 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766787145.576045    1568 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766787145.576049    1568 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n[INFO] Loading tokenizer for Mistral...\n[INFO] Loading Mistral-7B-v0.2 in 4-bit...\nLoading checkpoint shards: 100%|██████████████████| 3/3 [00:15<00:00,  5.15s/it]\n[INFO] LLM model loaded successfully on cuda:0\n[INFO] Embedding model 'sentence-transformers/all-MiniLM-L6-v2' loaded\nDevice set to use cuda:0\nThe following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n/kaggle/working/pipeline.py:28: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n  vector_db = Chroma(\n[INFO] Waiting for server to stabilize...\nPOST status: 200\nPOST response:\n{\n    \"question\": \"Which country left the Commonwealthin 1972 and rejoined in 1989?\",\n    \"answer\": \"Not found in context\",\n    \"retrieved_context\": \"formally relinquished rights 15 March 1991 Ghana: 6 March 1957 (from UK) Gibraltar : none (overseas territory of the UK) Greece: 1829 (from the Ottoman Empire) Greenland: none (part of the Kingdom of Denmark; self-governing overseas administrative division of Denmark since 1979) Grenada: 7 February 1974 (from UK) Guadeloupe: none (overseas department of France) Guam: none (territory of the US) Guatemala: 15 September 1821 (from Spain) Guernsey: none (British crown dependency) Guinea: 2 October 1958 (from France) Guinea-Bissau: 24 September 1973 (unilaterally declared by Guinea-Bissau); 10 September 1974 (recognized by Portugal) Guyana: 26 May 1966 (from UK) Haiti: 1 January 1804 (from France) Honduras: 15\\nformally relinquished rights 15 March 1991 Ghana: 6 March 1957 (from UK) Gibraltar : none (overseas territory of the UK) Greece: 1829 (from the Ottoman Empire) Greenland: none (part of the Kingdom of Denmark; self-governing overseas administrative division of Denmark since 1979) Grenada: 7 February 1974 (from UK) Guadeloupe: none (overseas department of France) Guam: none (territory of the US) Guatemala: 15 September 1821 (from Spain) Guernsey: none (British crown dependency) Guinea: 2 October 1958 (from France) Guinea-Bissau: 24 September 1973 (unilaterally declared by Guinea-Bissau); 10 September 1974 (recognized by Portugal) Guyana: 26 May 1966 (from UK) Haiti: 1 January 1804 (from France) Honduras: 15\\nformally relinquished rights 15 March 1991 Ghana: 6 March 1957 (from UK) Gibraltar : none (overseas territory of the UK) Greece: 1829 (from the Ottoman Empire) Greenland: none (part of the Kingdom of Denmark; self-governing overseas administrative division of Denmark since 1979) Grenada: 7 February 1974 (from UK) Guadeloupe: none (overseas department of France) Guam: none (territory of the US) Guatemala: 15 September 1821 (from Spain) Guernsey: none (British crown dependency) Guinea: 2 October 1958 (from France) Guinea-Bissau: 24 September 1973 (unilaterally declared by Guinea-Bissau); 10 September 1974 (recognized by Portugal) Guyana: 26 May 1966 (from UK) Haiti: 1 January 1804 (from France) Honduras: 15\\nMacmillan announced its decision to seek membership in the European Economic Community . Because of French opposition as well as Britain's request for special considerations for the countries of the Commonwealth and of EFTA, agreement on British entry was not reached until 1971. Britain finally entered what had become the European Community (now the European Union [EU]) in Jan., 1973. Labour returned to power in 1964 under Harold Wilson , and the steel industry was renationalized. The country faced the compound economic problems of a very unfavorable balance of trade, the instability of the pound sterling, a lagging rate of economic growth, and inflationary wages and prices. A number of sterling crises were followed by government controls and cutbacks. Britain supported U.S. policy in Vietnam. The policy of granting independence to colonial possessions continued; however, Rhodesia (see Zimbabwe ) became a problem when its government, representing only the white minority, unilaterally declared its independence in 1965. Another problem was Spain's demand for the return of Gibraltar. A major crisis erupted in Northern Ireland in late 1968 when\\nMacmillan announced its decision to seek membership in the European Economic Community . Because of French opposition as well as Britain's request for special considerations for the countries of the Commonwealth and of EFTA, agreement on British entry was not reached until 1971. Britain finally entered what had become the European Community (now the European Union [EU]) in Jan., 1973. Labour returned to power in 1964 under Harold Wilson , and the steel industry was renationalized. The country faced the compound economic problems of a very unfavorable balance of trade, the instability of the pound sterling, a lagging rate of economic growth, and inflationary wages and prices. A number of sterling crises were followed by government controls and cutbacks. Britain supported U.S. policy in Vietnam. The policy of granting independence to colonial possessions continued; however, Rhodesia (see Zimbabwe ) became a problem when its government, representing only the white minority, unilaterally declared its independence in 1965. Another problem was Spain's demand for the return of Gibraltar. A major crisis erupted in Northern Ireland in late 1968 when\",\n    \"latency_ms\": 9253\n}\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport time\nimport re\nfrom pipeline import run_rag\n\nevaluation_set = [\n    {\"question\": \"Which number Beethoven symphony is known as 'The Pastoral'?\", \"ground_truth\": \"Sixth\"},\n    {\"question\": \"Miami Beach in Florida borders which ocean?\", \"ground_truth\": \"Atlantic\"},\n    {\"question\": \"What is the name of the perfume launched by British boyband JLS in January 2013?\", \"ground_truth\": \"Love\"},\n    {\"question\": \"Caroline of Brunswick was the queen consort of which British King?\", \"ground_truth\": \"George IV\"},\n    {\"question\": \"What is the official march of the Royal Navy?\", \"ground_truth\": \"Heart of Oak\"},\n    {\"question\": \"Technically a shoal of fish becomes a school of fish when it is?\", \"ground_truth\": \"Swimming in the same direction\"},\n    {\"question\": \"On which island was the famous photograph taken showing US Marines raising the US flag over Mt Suribachi in February 1945?\", \"ground_truth\": \"Iwo Jima\"},\n    {\"question\": \"What was the first name of the character played by John Travolta in Saturday Night Fever?\", \"ground_truth\": \"Tony (Manero)\"},\n    {\"question\": \"Jonas Salk developed a vaccine against what?\", \"ground_truth\": \"Polio\"},\n    {\"question\": \"Who is said to have cut the Gordian Knot?\", \"ground_truth\": \"Alexander the Great\"},\n    {\"question\": \"The Italian cheese called dolcelatte translates into English as what?\", \"ground_truth\": \"Sweet milk\"},\n    {\"question\": \"What is the title of the last Harry Potter novel, published in 2007?\", \"ground_truth\": \"Harry Potter and the Deathly Hallows\"},\n    {\"question\": \"Who was the first professional cricketer to captain England?\", \"ground_truth\": \"Len Hutton\"},\n    {\"question\": \"Which country left the Commonwealth in 1972 and rejoined in 1989?\", \"ground_truth\": \"Pakistan\"},\n    {\"question\": \"Wisent is an alternative name for which animal?\", \"ground_truth\": \"(European) Bison\"},\n    {\"question\": \"In 1984, in Bophal, India, there was a leak of 30 tons of methyl isocyanate, which resulted in the deaths of 25,000 people. What American chemical company owned the plant where the leak occurred?\", \"ground_truth\": \"UNION CARBIDE\"},\n    {\"question\": \"In which country is the annual International Alphorn Festival held?\", \"ground_truth\": \"SWITZERLAND\"},\n    {\"question\": \"David Balfour and Alan Breck are characters in books by which author?\", \"ground_truth\": \"ROBERT LOUIS STEVENSON\"},\n    {\"question\": \"High Willhays is the highest point of what National Park?\", \"ground_truth\": \"DARTMOOR\"},\n    {\"question\": \"In 1973 the Paris Peace Accords were held in an attempt to end which war?\", \"ground_truth\": \"Vietnam\"}\n]\n\ndef normalize(text):\n    \"\"\"Remove punctuation, convert to lowercase, and strip spaces\"\"\"\n    return re.sub(r'[^\\w\\s]', '', text).lower().strip() if text else ''\n\ndef evaluate_system(test_set):\n    results = []\n    latencies = []\n\n    print(f\"Starting Evaluation on {len(test_set)} questions...\\n\")\n\n    for item in test_set:\n        q = item[\"question\"]\n        gt = item[\"ground_truth\"]\n\n        res = run_rag(q)\n        generated_ans = res.get(\"answer\", \"\").strip()\n        context = res.get(\"retrieved_context\", \"\")\n        latency = res.get(\"latency_ms\", 0)\n\n        latencies.append(latency)\n\n        # Normalize for comparison\n        gen_norm = normalize(generated_ans)\n        gt_norm = normalize(gt)\n        context_norm = normalize(context)\n\n        relevance = \"Yes\" if gt_norm in context_norm else \"No\"\n        context_ok = \"Yes\" if gt_norm in context_norm else \"No\"\n\n        # Evaluate correctness\n        if generated_ans == \"Not found in context\":\n            status = \"Incorrect\"\n        elif not context_ok:\n            status = \"Incorrect\"\n        elif gen_norm == gt_norm:\n            status = \"Correct\"\n        elif gt_norm in gen_norm or gen_norm in gt_norm:\n            status = \"Partially Correct\"\n        else:\n            status = \"Incorrect\"\n\n        results.append({\n            \"Question\": q,\n            \"Ground Truth\": gt,\n            \"RAG Answer\": generated_ans,\n            \"Context Correct?\": context_ok,\n            \"Evaluation Status\": status,\n            \"Latency (ms)\": latency,\n            \"Relevance\": relevance\n        })\n\n    df = pd.DataFrame(results)\n    accuracy = df[\"Evaluation Status\"].isin([\"Correct\", \"Partially Correct\"]).sum() / len(df) * 100\n    avg_latency = round(sum(latencies) / len(latencies), 2)\n    relevance_pct = (df[\"Relevance\"] == \"Yes\").sum() / len(df) * 100\n\n    print(\"\\n📊 Evaluation Summary\")\n    print(f\"Accuracy: {accuracy:.2f}%\")\n    print(f\"Average Latency: {avg_latency} ms\")\n    print(f\"Relevance: {relevance_pct:.2f}%\")\n\n    return df\n\n# Run evaluation\ndf_final_results = evaluate_system(evaluation_set)\ndf_final_results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T22:00:10.889457Z","iopub.execute_input":"2025-12-26T22:00:10.889731Z","iopub.status.idle":"2025-12-26T22:01:39.156987Z","shell.execute_reply.started":"2025-12-26T22:00:10.889703Z","shell.execute_reply":"2025-12-26T22:01:39.156272Z"}},"outputs":[{"name":"stdout","text":"Starting Evaluation on 20 questions...\n\n\n📊 Evaluation Summary\nAccuracy: 55.00%\nAverage Latency: 4411.5 ms\nRelevance: 50.00%\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"                                             Question  \\\n0   Which number Beethoven symphony is known as 'T...   \n1         Miami Beach in Florida borders which ocean?   \n2   What is the name of the perfume launched by Br...   \n3   Caroline of Brunswick was the queen consort of...   \n4       What is the official march of the Royal Navy?   \n5   Technically a shoal of fish becomes a school o...   \n6   On which island was the famous photograph take...   \n7   What was the first name of the character playe...   \n8        Jonas Salk developed a vaccine against what?   \n9           Who is said to have cut the Gordian Knot?   \n10  The Italian cheese called dolcelatte translate...   \n11  What is the title of the last Harry Potter nov...   \n12  Who was the first professional cricketer to ca...   \n13  Which country left the Commonwealth in 1972 an...   \n14    Wisent is an alternative name for which animal?   \n15  In 1984, in Bophal, India, there was a leak of...   \n16  In which country is the annual International A...   \n17  David Balfour and Alan Breck are characters in...   \n18  High Willhays is the highest point of what Nat...   \n19  In 1973 the Paris Peace Accords were held in a...   \n\n                            Ground Truth              RAG Answer  \\\n0                                  Sixth                   Sixth   \n1                               Atlantic          Atlantic Ocean   \n2                                   Love    Not found in context   \n3                              George IV               George IV   \n4                           Heart of Oak    Not found in context   \n5         Swimming in the same direction    Not found in context   \n6                               Iwo Jima                Iwo Jima   \n7                          Tony (Manero)             Tony Manero   \n8                                  Polio                   Polio   \n9                    Alexander the Great     Alexander the Great   \n10                            Sweet milk       Sweet blue cheese   \n11  Harry Potter and the Deathly Hallows         Deathly Hallows   \n12                            Len Hutton           Mike Brearley   \n13                              Pakistan          Bahamas (left)   \n14                      (European) Bison                 Aurochs   \n15                         UNION CARBIDE           Union Carbide   \n16                           SWITZERLAND    Not found in context   \n17                ROBERT LOUIS STEVENSON  Robert Louis Stevenson   \n18                              DARTMOOR     Blackfoot Mountains   \n19                               Vietnam             Vietnam War   \n\n   Context Correct?  Evaluation Status  Latency (ms) Relevance  \n0               Yes            Correct          2049       Yes  \n1               Yes  Partially Correct          2578       Yes  \n2                No          Incorrect          6395        No  \n3               Yes            Correct          2470       Yes  \n4                No          Incorrect          5042        No  \n5                No          Incorrect          9221        No  \n6               Yes            Correct          2652       Yes  \n7               Yes            Correct          4946       Yes  \n8               Yes            Correct          6692       Yes  \n9               Yes            Correct          2535       Yes  \n10               No          Incorrect          9205        No  \n11               No  Partially Correct          2677        No  \n12               No          Incorrect          2651        No  \n13              Yes          Incorrect          7374       Yes  \n14               No          Incorrect          9128        No  \n15              Yes            Correct          2590       Yes  \n16               No          Incorrect          2983        No  \n17               No            Correct          2769        No  \n18               No          Incorrect          1796        No  \n19              Yes  Partially Correct          2477       Yes  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Ground Truth</th>\n      <th>RAG Answer</th>\n      <th>Context Correct?</th>\n      <th>Evaluation Status</th>\n      <th>Latency (ms)</th>\n      <th>Relevance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Which number Beethoven symphony is known as 'T...</td>\n      <td>Sixth</td>\n      <td>Sixth</td>\n      <td>Yes</td>\n      <td>Correct</td>\n      <td>2049</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Miami Beach in Florida borders which ocean?</td>\n      <td>Atlantic</td>\n      <td>Atlantic Ocean</td>\n      <td>Yes</td>\n      <td>Partially Correct</td>\n      <td>2578</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What is the name of the perfume launched by Br...</td>\n      <td>Love</td>\n      <td>Not found in context</td>\n      <td>No</td>\n      <td>Incorrect</td>\n      <td>6395</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Caroline of Brunswick was the queen consort of...</td>\n      <td>George IV</td>\n      <td>George IV</td>\n      <td>Yes</td>\n      <td>Correct</td>\n      <td>2470</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What is the official march of the Royal Navy?</td>\n      <td>Heart of Oak</td>\n      <td>Not found in context</td>\n      <td>No</td>\n      <td>Incorrect</td>\n      <td>5042</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Technically a shoal of fish becomes a school o...</td>\n      <td>Swimming in the same direction</td>\n      <td>Not found in context</td>\n      <td>No</td>\n      <td>Incorrect</td>\n      <td>9221</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>On which island was the famous photograph take...</td>\n      <td>Iwo Jima</td>\n      <td>Iwo Jima</td>\n      <td>Yes</td>\n      <td>Correct</td>\n      <td>2652</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>What was the first name of the character playe...</td>\n      <td>Tony (Manero)</td>\n      <td>Tony Manero</td>\n      <td>Yes</td>\n      <td>Correct</td>\n      <td>4946</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Jonas Salk developed a vaccine against what?</td>\n      <td>Polio</td>\n      <td>Polio</td>\n      <td>Yes</td>\n      <td>Correct</td>\n      <td>6692</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Who is said to have cut the Gordian Knot?</td>\n      <td>Alexander the Great</td>\n      <td>Alexander the Great</td>\n      <td>Yes</td>\n      <td>Correct</td>\n      <td>2535</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>The Italian cheese called dolcelatte translate...</td>\n      <td>Sweet milk</td>\n      <td>Sweet blue cheese</td>\n      <td>No</td>\n      <td>Incorrect</td>\n      <td>9205</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>What is the title of the last Harry Potter nov...</td>\n      <td>Harry Potter and the Deathly Hallows</td>\n      <td>Deathly Hallows</td>\n      <td>No</td>\n      <td>Partially Correct</td>\n      <td>2677</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Who was the first professional cricketer to ca...</td>\n      <td>Len Hutton</td>\n      <td>Mike Brearley</td>\n      <td>No</td>\n      <td>Incorrect</td>\n      <td>2651</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Which country left the Commonwealth in 1972 an...</td>\n      <td>Pakistan</td>\n      <td>Bahamas (left)</td>\n      <td>Yes</td>\n      <td>Incorrect</td>\n      <td>7374</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Wisent is an alternative name for which animal?</td>\n      <td>(European) Bison</td>\n      <td>Aurochs</td>\n      <td>No</td>\n      <td>Incorrect</td>\n      <td>9128</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>In 1984, in Bophal, India, there was a leak of...</td>\n      <td>UNION CARBIDE</td>\n      <td>Union Carbide</td>\n      <td>Yes</td>\n      <td>Correct</td>\n      <td>2590</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>In which country is the annual International A...</td>\n      <td>SWITZERLAND</td>\n      <td>Not found in context</td>\n      <td>No</td>\n      <td>Incorrect</td>\n      <td>2983</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>David Balfour and Alan Breck are characters in...</td>\n      <td>ROBERT LOUIS STEVENSON</td>\n      <td>Robert Louis Stevenson</td>\n      <td>No</td>\n      <td>Correct</td>\n      <td>2769</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>High Willhays is the highest point of what Nat...</td>\n      <td>DARTMOOR</td>\n      <td>Blackfoot Mountains</td>\n      <td>No</td>\n      <td>Incorrect</td>\n      <td>1796</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>In 1973 the Paris Peace Accords were held in a...</td>\n      <td>Vietnam</td>\n      <td>Vietnam War</td>\n      <td>Yes</td>\n      <td>Partially Correct</td>\n      <td>2477</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":40}]}